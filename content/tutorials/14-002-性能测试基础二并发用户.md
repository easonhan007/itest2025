---
weight: 2
title: 性能测试基础（二）并发用户
date: '2017-08-11T14:59:11+08:00'
lastmod: '2025-06-17T17:29:15+08:00'
draft: false
author: 虫师
authorLink: https://github.com/defnngj
images: []
resources:
- name: featured-image
  src: https://images.unsplash.com/photo-1468930830753-6699377de411?w=300
tags: []
categories:
- 性能测试基础教程
lightgallery: true
toc:
  auto: false
---



<br>
![](http://img.testclass.net/vusers.png)
<br>
#### 并发的两种情况
----
一种是严格意义上的并发，即所有的用户在同一时间点做同一件事或操作，这种操作一般指做同一类型的业务。比如，所有用户同一时刻做并发登陆，同一时刻做表单提交。

另外一种并发是广义范围的并发，这种并发与前一种并发的区别是，尽管多个用户对系统发出了请求或者进行了操作，但是这些请求或都操作可以是相同的，也可以是不同的。比如，在同一时刻有用户在登录，有用户在提交表单。

<br> 
### 从服务器的角度来看并发
----
前面的两种解释都是从用户业务的角度来解释并发的，因为我们平时所做的性能测试也是从用户端对业务层的操作来进行并发测试的。

如果考虑整个系统运行过程中服务器所承受的压力是这样的：在该系统的运行过程中，把整个运行过程划分为离散的时间点，在每个点上都有一个“同时向服务端发送请求的用户数”，这个就是所谓的服务器所承受的并发访问数。

<br>
#### 真正意义上的并发不存在
----

从性能测试工具的角度来看，虽然，性能测试工具可以1秒模拟成千上万个请求，那么这些请求的产生同样分前后顺序。就算这些请求被真正的“同时”生产出来，通过网络传输到过服务器时，因为受网络带宽、延迟等影响，也无法真正的对服务器构成“同时”请求。

从服务器角度，当它接收到并发请求，在处理这些请求时同样需要分前后顺序，因为它处理每个请求的时间极短；每秒可以处理几千几万次请求；所以，我们说它的并发能力是每秒/次。

（__注：__ 这里假设模拟虚拟用户的服务器和系统服务器为单核CPU的情况下）

<br>
#### 系统用户数与同时在线人数
----

在实际的性能测试中，经常还会遇到与并发相关的两个概念“系统用户数”与“同时在线人数”。

假设有一个网站，注册用户才能登录使用各种功能，如上传头像，阅读专家文章等。该系统有20万注册用户，这就是说有20万用户可以使用这个网站的所有功能，20万就是这个网站的“系统用户数”，网站有一个在线统计功能，从统计数据中可以看到，同时登录网站的人数的最高记录是2万，就是有2万人同时用浏览器打开着这个网站。2万就是“同时在线人数”。
那么系统的并发用户数2万么？不是的！这2万只表示在系统最高峰时有这么多用户登录了网站，并不代表服务器的实际承受压力。因为服务器承受压力还与具体的用户访问模式相关，在这2万用户中考察某一个时间点对用户发出请求数，可以会大大缩水。那么，该系统的服务端承受的最大并发访问数是多少呢？这个取决于业务并发用户数和业务场景，一般可以通过服务器日志的分析得到。




原始封面

![课程图片](https://images.unsplash.com/photo-1468930830753-6699377de411?w=300)

