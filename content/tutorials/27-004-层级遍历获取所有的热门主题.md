---
weight: 4
title: 层级遍历:获取所有的热门主题
date: '2017-12-15T02:52:34+08:00'
lastmod: '2025-06-17T17:29:15+08:00'
draft: false
author: 乙醇
authorLink: https://github.com/easonhan007
images: []
resources:
- name: featured-image
  src: https://images.unsplash.com/photo-1472396961693-142e6e269027?w=300
tags: []
categories:
- 如何实现网络爬虫
lightgallery: true
toc:
  auto: false
---



### 稍微复杂一点的例子

在[v2ex](https://www.v2ex.com/)主页的右侧一般有个最热主题区域，里面列出了当日的热门讨论话题。这一节里我们就尝试使用爬虫技术获取这些热门主题文本和链接。

**注意：v2ex本身提供了接口去获取这些热门主题的详细信息，本节内容只是举例，并不是最佳实践**

具体步骤

* 访问v2ex主页，获取html文本
* 分析html文本，找出待获取内容的特征
* 解析html代码，根据特征拿出目标内容
* 打印这些内容


### 分析html代码

热门内容部分的html代码如下所示

```html
<span class="item_hot_topic_title">
  <a href="/t/415664">冬天了，身上静电咋处理？</a>
</span>
```

可以看出我们要找到的是所有class=item_hot_topic_title的span下面的a元素

### 代码

新建名为```v2ex_hosts.py```的文件，输入下面的内容

```python

import requests
from bs4 import BeautifulSoup

url = 'https://www.v2ex.com/'
soup = BeautifulSoup(requests.get(url).text, 'html.parser')

for span in soup.find_all('span', class_='item_hot_topic_title'):
    print(span.find('a').text, span.find('a')['href'])
```

### 运行

在命令行中输入

```
python v2ex_hosts.py
```

### 预期结果

如果一切正常，那么应该可以看到**类似**下面的结果，由于每天的热门主题不一样，所以内容是会变化的

```
小米感恩节不感恩 /t/415623
冬天了，身上静电咋处理？ /t/415664
违反一下政治正确，骂一下 Google /t/415600
做了将近 6 年程序员，没能成为大牛，考虑再三，决定改行，大家说，做点什么好呢？ /t/415701
结果还是被雷猴王给套路了 /t/415843
一直很好奇 Mac+安卓的组合是基于什么优势考虑的呢？ /t/415645
听说比特币要分叉了？ /t/415858
看到大学同学朋友圈发的北大成人通知书，心里不是滋味。 /t/415821
当码农 8 年了，要不要去读个研 /t/415854
新进一家公司遭遇的待遇~~ /t/415863
```

### 我们可以学到什么

* ```for span in soup.find_all('span', class_='item_hot_topic_title')```: 遍历所有的class=item_hot_topic_title的span。注意是```class_```，不是```class```，因为class是python的关键字，所以后面要加个尾巴，防止冲突

* ```span.find('a').text```：层级遍历，先找到span，再从span下找到a，这是常用套路

* ```span.find('a')['href']```：获取href属性，在bs4里，我们可以通过```[attribute_name]```的方式来获取元素的属性


### 阅读内容

BeautifulSoup

* [find_all](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all)
* [find](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find)
* [css_selector](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors)
* [attributes](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#attributes)




原始封面

![课程图片](https://images.unsplash.com/photo-1472396961693-142e6e269027?w=300)

